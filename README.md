# ML-Web: Сервис анализа тональности обращений горожан

## 1. Цель и постановка задачи
Город получает большое количество отзывов и обращений жителей. Чтобы быстрее реагировать на жалобы, понимать, какие цифровые сервисы нравятся людям, и эффективно распределять ресурсы, требуется автоматический анализ тональности сообщений. В рамках проекта нужно создать ML-модель для классификации русскоязычных текстов и веб-приложение, позволяющее:

- **Контекст кейса:** «Отзывы горожан — ценная информация, которая помогает столице развивать цифровые сервисы. Анализировать вручную огромный массив комментариев сложно, поэтому необходимо автоматизировать определение тональности обращений и предоставить интерфейс для взаимодействия с моделью» (ML/Web: построение модели дохода).

- вводить текст обращения;
- получать класс тональности (`positive`, `neutral`, `negative`);
- видеть вероятности по каждому классу для объяснимости;
- (опционально) просматривать статистику и графики.

## 2. Требования к ML-модели
### 2.1 Входные и выходные данные
- **Вход:** строка текста на русском языке (один отзыв/сообщение).
- **Выход:**
  - класс тональности (`positive`, `negative`, `neutral`), расширяемый `mixed` или тематическими классами;
  - вероятности по каждому классу (например, `{positive: 0.8, neutral: 0.15, negative: 0.05}`).

### 2.2 Данные
- **Источники:** порталы (активный гражданин, mos.ru), соцсети, внутренние логи обращений.
- **Разметка:** каждая запись помечена `positive` / `negative` / `neutral`. Если разметки нет — провести ручную разметку или использовать открытые корпуса.
- **Объём:** от 5–10 тыс. текстов и больше, особенно для трансформеров.
- **Предобработка:**
  - для классических моделей — очистка HTML, приведение к нижнему регистру, нормализация ссылок/эмодзи, лемматизация (pymorphy2, Natasha), удаление стоп-слов при необходимости;
  - для BERT-моделей — использовать встроенный токенизатор, ограничивать длину (256–512 токенов).

### 2.3 Модели
- **Бейзлайн:** TF-IDF + Logistic Regression / Linear SVM / Random Forest.
- **Современный вариант:** трансформеры для русского (RuBERT, ruRoBERTa, XLM-R, rubert-tiny) с дообучением.

### 2.4 Метрики
- Accuracy.
- Macro F1-score (важно при дисбалансе классов).
- Confusion matrix для анализа ошибок. Целевые значения зависят от датасета (ориентир: F1-macro ≥ 0.8–0.85).

## 3. ML-пайплайн
1. **EDA:** распределение классов, длины текстов, примеры шума.
2. **Предобработка:** чистка, сплит на train/val/test (например, 70/15/15).
3. **Бейзлайн:** TF-IDF + логистическая регрессия, оценка на валидации/тесте.
4. **Трансформеры:** загрузка предобученной модели (RuBERT), финетюнинг с подбором hyperparameters (learning rate, batch size, epochs).
5. **Анализ ошибок:** сарказм, короткие сообщения, смешанные отзывы.
6. **Сохранение модели:** сериализация (joblib/pickle для классических моделей или `transformers` + `torch` для BERT), хранение метаданных (дата, параметры).

## 4. Backend
### 4.1 Архитектура
- Рекомендуемый фреймворк — FastAPI (альтернатива: Flask, Django REST).
- При старте backend загружает модель и инициализирует `SentimentClassifier`.
- Основные эндпоинты:
  - `POST /predict`: тело `{ "text": "Ваш сервис работает ужасно медленно!" }`, ответ — класс и вероятности.
  - (Опционально) `POST /predict_batch` для списков текстов.
  - `GET /health` для health-check.
  - `GET /stats` для статистики (если храните историю запросов).

### 4.2 Производительность
- Тёплый старт модели (загрузка один раз).
- Ограничение длины текста (1–2k символов или 512 токенов).
- По необходимости — асинхронная обработка или очереди задач.

## 5. Frontend
### 5.1 Минимальный функционал
- Страница с формой ввода текста, кнопкой «Анализировать» и отображением результата (цветовая индикация тональности и вероятностей).

### 5.2 Дополнительные фичи
- История запросов.
- Обработка списка отзывов (например, загрузка CSV) и отображение статистики (pie chart, bar chart).
- Форма обратной связи для корректировки предсказаний (active learning).

### 5.3 Технологии
- Любой стек (React/Vue/Angular или чистый HTML+CSS+JS).
- Главное — корректно отправлять запросы к API и визуализировать результаты.

## 6. UX/UI
- Понятный интерфейс для нетехнических пользователей: поле ввода, кнопка, объяснение результата.
- Цветовое кодирование тональностей, простые графики, адаптив под desktop/mobile.
- Типичный сценарий: пользователь вводит отзыв и сразу видит результат с пояснением.

## 7. Инфраструктура и деплой
- Docker-контейнеры для backend (с моделью) и frontend (или отдача статики через nginx).
- Web-сервер/reverse proxy (nginx) для маршрутизации.
- Сервер/облако (для учебного кейса не критично).
- Логирование запросов и ошибок, версионирование в Git.

## 8. Роли в команде
- **Data Scientist/Data Engineer:** данные, EDA, обучение, метрики, документация.
- **Backend Developer:** API, интеграция с моделью, очереди, логирование, деплой.
- **Frontend Developer:** UI, интеграция с API, адаптив.
- **UX/UI Designer:** прототипы, дизайн, user flow. (Опционально — Project Manager.)

## 9. Возможные расширения
- Классификация по аспектам (интерфейс, скорость, удобство и т.д.).
- Тематическая классификация (транспорт, ЖКХ, медицина, образование).
- Active Learning: интерфейс для исправления ошибок модели и последующего дообучения.
- Explainability: подсветка ключевых фраз (LIME, SHAP, визуализация attention).

## 10. Этапы реализации
1. Сбор и анализ данных.
2. Предобработка и подготовка разметки.
3. Создание бейзлайна и измерение метрик.
4. Финетюнинг трансформерной модели и улучшение качества.
5. Разработка backend API и интеграция с моделью.
6. Реализация frontend-интерфейса.
7. Настройка инфраструктуры, Docker и деплой.
8. Сбор обратной связи, анализ ошибок, дальнейшие улучшения.

README служит планом проекта. На следующих этапах реализуем каждый компонент последовательно, чтобы вся система корректно обучалась, запускалась и была готова к демонстрации.

## 11. Текущий прогресс реализации

### 11.1 Структура репозитория

```
├── backend/
│   └── app/
│       ├── main.py          # FastAPI-приложение, статика, эндпоинты predict/stats/model
│       ├── model.py         # Загрузка ML-модели и fallback-классификатор
│       ├── schemas.py       # Pydantic-схемы запросов, ответов и статистики
│       └── stats.py         # In-memory сбор статистики и истории
├── data/
│   └── sample_reviews.csv   # Мини-датасет (30 размеченных отзывов)
├── frontend/
│   ├── index.html           # UI: ввод текста, результаты, графики
│   ├── styles.css
│   └── app.js
├── ml/
│   └── train_baseline.py    # Скрипт обучения TF-IDF + Logistic Regression
├── models/
│   └── (baseline.joblib, metadata.json)  # появляются после обучения
├── requirements.txt
└── README.md
```

### 11.2 Быстрый старт
1. **Установите зависимости:** `make install` (аналог `pip install -r requirements.txt`).
2. **Проведите EDA или обучение:** `make eda` для генерации отчёта `reports/eda_summary.json`, затем `make train` для создания `models/baseline.joblib` и `models/metadata.json`.
3. **Запустите backend:** `make serve` или `uvicorn backend.app.main:app --reload`.
4. **Откройте UI:** FastAPI автоматически раздаёт статику из папки `frontend` по адресу `http://127.0.0.1:8000/ui`. Там можно вводить тексты, смотреть вероятности, историю и графики.
5. **Docker-режим:** `docker compose up --build` поднимет сервис с тем же API и фронтендом (см. раздел 11.7).

> ⚠️ Если PyPI недоступен, установите зависимости из локального зеркала. Без обученной модели API автоматически использует `KeywordFallbackModel`, поэтому можно тестировать весь стек до запуска обучения.

### 11.3 API

| Метод | Путь            | Описание |
|-------|-----------------|----------|
| `GET` | `/health`       | Health-check сервиса |
| `POST`| `/predict`      | Классификация одного текста, возвращает класс и вероятности |
| `POST`| `/predict_batch`| Пакетная классификация списка отзывов |
| `GET` | `/stats`        | Агрегированная статистика (кол-во запросов, доли классов, последние обращения) |
| `GET` | `/model`        | Метаданные обученной модели (алгоритм, классы, метрики) |

Документация FastAPI доступна по `/docs` (Swagger) и `/redoc`.

### 11.4 Фронтенд
- **Интерфейс:** чистый HTML/CSS/JS без сборщиков — достаточно открыть `/ui`.
- **Функции:** ввод текста, отображение тональности и вероятностей, doughnut-график распределения, список последних обращений, карточки с информацией о модели и количестве предсказаний.
- **API-интеграция:** `fetch` запросы к `/predict`, `/stats`, `/model`. Обновление статистики каждые 5 секунд.

### 11.5 ML-скрипты и данные
- `ml/train_baseline.py` строит пайплайн TF-IDF + Logistic Regression с балансировкой классов и сохраняет классификационный отчёт в метаданных.
- `data/sample_reviews.csv` — демо-датасет на 30 записей (по 10 положительных/отрицательных/нейтральных). Его можно заменить собственными данными с такими же колонками (`text`, `label`).

### 11.6 EDA и анализ данных
- `ml/eda.py` выполняет быстрый разведочный анализ: считает распределение классов, средние длины текстов, топовые токены. Результат выводится в консоль и сохраняется в `reports/eda_summary.json`. Для запуска: `python ml/eda.py --data data/sample_reviews.csv`.

### 11.7 Docker и автоматизация
- `Dockerfile` описывает образ Python 3.11, устанавливающий зависимости и запускающий Uvicorn.
- `docker-compose.yml` поднимает сервис `api`, монтирует локальные папки `models/`, `data/` и `frontend/`, пробрасывает порт `8000`.
- `Makefile` упрощает основные действия: `make install`, `make train`, `make eda`, `make serve`, `make docker-up`, `make docker-down`.

### 11.6 Следующие шаги
- Подключить расширенный корпус и добавить трансформер (RuBERT / ruRoBERTa) для улучшения качества.
- Расширить API для приёма файлов (CSV) и сохранения фидбэка пользователей (active learning).
- Упаковать backend+frontend в Docker и настроить CI/CD для автоматического развёртывания.
