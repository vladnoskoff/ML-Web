# ML-Web: Сервис анализа тональности обращений горожан

## 1. Цель и постановка задачи
Город получает большое количество отзывов и обращений жителей. Чтобы быстрее реагировать на жалобы, понимать, какие цифровые сервисы нравятся людям, и эффективно распределять ресурсы, требуется автоматический анализ тональности сообщений. В рамках проекта нужно создать ML-модель для классификации русскоязычных текстов и веб-приложение, позволяющее:

- вводить текст обращения;
- получать класс тональности (`positive`, `neutral`, `negative`);
- видеть вероятности по каждому классу для объяснимости;
- (опционально) просматривать статистику и графики.

## 2. Требования к ML-модели
### 2.1 Входные и выходные данные
- **Вход:** строка текста на русском языке (один отзыв/сообщение).
- **Выход:**
  - класс тональности (`positive`, `negative`, `neutral`), расширяемый `mixed` или тематическими классами;
  - вероятности по каждому классу (например, `{positive: 0.8, neutral: 0.15, negative: 0.05}`).

### 2.2 Данные
- **Источники:** порталы (активный гражданин, mos.ru), соцсети, внутренние логи обращений.
- **Разметка:** каждая запись помечена `positive` / `negative` / `neutral`. Если разметки нет — провести ручную разметку или использовать открытые корпуса.
- **Объём:** от 5–10 тыс. текстов и больше, особенно для трансформеров.
- **Предобработка:**
  - для классических моделей — очистка HTML, приведение к нижнему регистру, нормализация ссылок/эмодзи, лемматизация (pymorphy2, Natasha), удаление стоп-слов при необходимости;
  - для BERT-моделей — использовать встроенный токенизатор, ограничивать длину (256–512 токенов).

### 2.3 Модели
- **Бейзлайн:** TF-IDF + Logistic Regression / Linear SVM / Random Forest.
- **Современный вариант:** трансформеры для русского (RuBERT, ruRoBERTa, XLM-R, rubert-tiny) с дообучением.

### 2.4 Метрики
- Accuracy.
- Macro F1-score (важно при дисбалансе классов).
- Confusion matrix для анализа ошибок. Целевые значения зависят от датасета (ориентир: F1-macro ≥ 0.8–0.85).

## 3. ML-пайплайн
1. **EDA:** распределение классов, длины текстов, примеры шума.
2. **Предобработка:** чистка, сплит на train/val/test (например, 70/15/15).
3. **Бейзлайн:** TF-IDF + логистическая регрессия, оценка на валидации/тесте.
4. **Трансформеры:** загрузка предобученной модели (RuBERT), финетюнинг с подбором hyperparameters (learning rate, batch size, epochs).
5. **Анализ ошибок:** сарказм, короткие сообщения, смешанные отзывы.
6. **Сохранение модели:** сериализация (joblib/pickle для классических моделей или `transformers` + `torch` для BERT), хранение метаданных (дата, параметры).

## 4. Backend
### 4.1 Архитектура
- Рекомендуемый фреймворк — FastAPI (альтернатива: Flask, Django REST).
- При старте backend загружает модель и инициализирует `SentimentClassifier`.
- Основные эндпоинты:
  - `POST /predict`: тело `{ "text": "Ваш сервис работает ужасно медленно!" }`, ответ — класс и вероятности.
  - (Опционально) `POST /predict_batch` для списков текстов.
  - `GET /health` для health-check.
  - `GET /stats` для статистики (если храните историю запросов).

### 4.2 Производительность
- Тёплый старт модели (загрузка один раз).
- Ограничение длины текста (1–2k символов или 512 токенов).
- По необходимости — асинхронная обработка или очереди задач.

## 5. Frontend
### 5.1 Минимальный функционал
- Страница с формой ввода текста, кнопкой «Анализировать» и отображением результата (цветовая индикация тональности и вероятностей).

### 5.2 Дополнительные фичи
- История запросов.
- Обработка списка отзывов (например, загрузка CSV) и отображение статистики (pie chart, bar chart).
- Форма обратной связи для корректировки предсказаний (active learning).

### 5.3 Технологии
- Любой стек (React/Vue/Angular или чистый HTML+CSS+JS).
- Главное — корректно отправлять запросы к API и визуализировать результаты.

## 6. UX/UI
- Понятный интерфейс для нетехнических пользователей: поле ввода, кнопка, объяснение результата.
- Цветовое кодирование тональностей, простые графики, адаптив под desktop/mobile.
- Типичный сценарий: пользователь вводит отзыв и сразу видит результат с пояснением.

## 7. Инфраструктура и деплой
- Docker-контейнеры для backend (с моделью) и frontend (или отдача статики через nginx).
- Web-сервер/reverse proxy (nginx) для маршрутизации.
- Сервер/облако (для учебного кейса не критично).
- Логирование запросов и ошибок, версионирование в Git.

## 8. Роли в команде
- **Data Scientist/Data Engineer:** данные, EDA, обучение, метрики, документация.
- **Backend Developer:** API, интеграция с моделью, очереди, логирование, деплой.
- **Frontend Developer:** UI, интеграция с API, адаптив.
- **UX/UI Designer:** прототипы, дизайн, user flow. (Опционально — Project Manager.)

## 9. Возможные расширения
- Классификация по аспектам (интерфейс, скорость, удобство и т.д.).
- Тематическая классификация (транспорт, ЖКХ, медицина, образование).
- Active Learning: интерфейс для исправления ошибок модели и последующего дообучения.
- Explainability: подсветка ключевых фраз (LIME, SHAP, визуализация attention).

## 10. Этапы реализации
1. Сбор и анализ данных.
2. Предобработка и подготовка разметки.
3. Создание бейзлайна и измерение метрик.
4. Финетюнинг трансформерной модели и улучшение качества.
5. Разработка backend API и интеграция с моделью.
6. Реализация frontend-интерфейса.
7. Настройка инфраструктуры, Docker и деплой.
8. Сбор обратной связи, анализ ошибок, дальнейшие улучшения.

README служит планом проекта. На следующих этапах реализуем каждый компонент последовательно, чтобы вся система корректно обучалась, запускалась и была готова к демонстрации.

## 11. Текущий прогресс реализации

### 11.1 Структура репозитория

```
├── backend/            # FastAPI-приложение (эндпоинты predict/predict_batch/health)
│   └── app/
│       ├── main.py     # Точки входа API
│       ├── model.py    # Загрузка ML-модели и правила фолбэка
│       └── schemas.py  # Pydantic-схемы запросов/ответов
├── data/
│   └── sample_reviews.csv   # Пример размеченных отзывов
├── ml/
│   └── train_baseline.py    # Скрипт обучения TF-IDF + Logistic Regression
├── models/
│   └── (baseline.joblib, metadata.json)  # создаются после обучения
├── requirements.txt
└── README.md
```

### 11.2 Как обучить базовую модель
1. Установить зависимости: `pip install -r requirements.txt`.
2. Убедиться, что подготовлен размеченный CSV в `data/` (по умолчанию используется `data/sample_reviews.csv`).
3. Запустить обучение: `python ml/train_baseline.py`.
4. После завершения появятся файлы `models/baseline.joblib` и `models/metadata.json`.

> ⚠️ Если в окружении нет доступа к PyPI, FastAPI/Sklearn можно установить заранее или использовать локальное зеркало. Пока модель не обучена, backend автоматически переключится на простую keyword-модель, чтобы сервис оставался рабочим.

### 11.3 Запуск backend
1. Убедиться, что модель обучена (см. пункт 11.2) или используется фолбэк.
2. Запустить сервер: `uvicorn backend.app.main:app --reload`.
3. Проверить документацию по адресу `http://127.0.0.1:8000/docs` и протестировать эндпоинты `/predict`, `/predict_batch`, `/health`.

### 11.4 Следующие шаги
- Добавить более крупный датасет и сравнить метрики бейзлайна с трансформером.
- Подключить сохранение истории запросов и статистику для frontend.
- Реализовать клиентский интерфейс (SPA/SSR) и подготовить Docker-окружение.
